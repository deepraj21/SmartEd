{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uVT3TQ7sMY7"
   },
   "source": [
    "# PaLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VF1KrU4urUJP"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-rY42uSnXbOG"
   },
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyB5v4JcdsO0gLlgPhSkPD6CZYefcWY7aHk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1694762523170,
     "user": {
      "displayName": "Gopal Sharma",
      "userId": "12839894256006393174"
     },
     "user_tz": -330
    },
    "id": "6Yz70ZNltkdy",
    "outputId": "30c2a4c8-7af9-4aa7-99f4-26a491e53255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "# Use the palm.list_models function to find available models:\n",
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQW9eevUj8ly"
   },
   "source": [
    "## Problem Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EtkLIA_FttPG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-thought:\n",
      "First find the total number of cats: 3 houses * 3 cats / house = 9 cats. Then multiply the number of cats by the number of mittens per cat to find the total number of mittens: 9 cats * 4 mittens / cat = 36 mittens. Then multiply the number of mittens by the length of yarn per mitten to find the total length of yarn used for mittens: 36 mittens * 7m / mitten = 252m. Then multiply the number of cats by the number of hats per cat to find the total number of hats: 9 cats * 1 hat / cat = 9 hats. Then multiply the number of hats by the length of yarn per hat to find the total length of yarn used for hats: 9 hats * 4m / hat = 36m. Then add the length of yarn used for mittens and hats to find the total length of yarn used: 252m + 36m = 288m.\n",
      "\n",
      "The answer should be 288\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert at solving word problems.\n",
    "\n",
    "Solve the following problem:\n",
    "\n",
    "I have three houses, each with three cats.\n",
    "each cat owns 4 mittens, and a hat. Each mitten was\n",
    "knit from 7m of yarn, each hat from 4m.\n",
    "How much yarn was needed to make all the items?\n",
    "\n",
    "Think about it step by step, and show your work.\n",
    "\"\"\"\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2273,
     "status": "ok",
     "timestamp": 1694762828111,
     "user": {
      "displayName": "Gopal Sharma",
      "userId": "12839894256006393174"
     },
     "user_tz": -330
    },
    "id": "DFnfJtYbXd_E",
    "outputId": "339bf070-8e13-45f0-846c-a094b40a8bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Home Remedies for Fever**\n",
      "\n",
      "* **Rest**. Getting plenty of rest is essential for helping your body fight off the infection that is causing your fever.\n",
      "* **Drink plenty of fluids**. Staying hydrated is important for preventing dehydration, which can worsen your symptoms.\n",
      "* **Apply a cool compress to your forehead**. This can help to reduce your fever and provide relief from discomfort.\n",
      "* **Take a lukewarm bath or shower**. This can also help to lower your fever and relieve symptoms.\n",
      "* **Use over-the-counter pain relievers**, such as acetaminophen or ibuprofen, to help relieve fever and other symptoms.\n",
      "\n",
      "**Medicines for Fever**\n",
      "\n",
      "* **Acetaminophen** (Tylenol)\n",
      "* **Ibuprofen** (Advil, Motrin)\n",
      "* **Aspirin** (should not be used for children under 18)\n",
      "* **Naproxen** (Aleve)\n",
      "\n",
      "It is important to talk to your doctor before taking any medication, especially if you have any underlying health conditions.\n"
     ]
    }
   ],
   "source": [
    "# Set your input text\n",
    "# prompt = \"Why is the sky blue?\"\n",
    "prompt = \"I am Having Fever for 2 days tell me some home remidies and medicine names keep it under 200 words\"\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=500,\n",
    ")\n",
    "\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NU1b3f5kdkc"
   },
   "source": [
    "## Custom Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0pzfK-gkzJU"
   },
   "source": [
    "### Text Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P6-zH35Dw0Xm"
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "n6d42reCXq7w"
   },
   "outputs": [],
   "source": [
    "filename  = 'Art-of-War.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYpNlLqcZVyw"
   },
   "outputs": [],
   "source": [
    "# creating a pdf file object\n",
    "pdfFileObject = open(directory+filename, 'rb')\n",
    "# creating a pdf reader object\n",
    "pdfReader = PdfReader(pdfFileObject)\n",
    "text=[]\n",
    "summary=' '\n",
    "#Storing the pages in a list\n",
    "for i in range(0,len(pdfReader.pages)):\n",
    "  # creating a page object\n",
    "  pageObj = pdfReader.pages[i].extract_text()\n",
    "  pageObj= pageObj.replace('\\t\\r','')\n",
    "  pageObj= pageObj.replace('\\xa0','')\n",
    "  # extracting text from page\n",
    "  text.append(pageObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1694762878206,
     "user": {
      "displayName": "Gopal Sharma",
      "userId": "12839894256006393174"
     },
     "user_tz": -330
    },
    "id": "0y8iM7trjKdM",
    "outputId": "8d28050f-7e0e-46a7-c4a5-edb0835ab8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Pages =  15\n",
      "Compressed Pages =  5\n"
     ]
    }
   ],
   "source": [
    "# Merge multiple page - to reduce API Calls\n",
    "def join_elements(lst, chars_per_element):\n",
    "    new_lst = []\n",
    "    for i in range(0, len(lst), chars_per_element):\n",
    "        new_lst.append(''.join(lst[i:i+chars_per_element]))\n",
    "    return new_lst\n",
    "\n",
    "# Option to keep x elements per list element\n",
    "new_text = join_elements(text, 3)\n",
    "\n",
    "print(f\"Original Pages = \",len(text))\n",
    "print(f\"Compressed Pages = \",len(new_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ_lIoBzX267"
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "  completion = palm.generate_text(model=model,\n",
    "                                  prompt=prompt,\n",
    "                                  temperature=0,\n",
    "                                  # The maximum length of the response\n",
    "                                  max_output_tokens=200,\n",
    "                                  )\n",
    "  return completion.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102932,
     "status": "ok",
     "timestamp": 1694763645515,
     "user": {
      "displayName": "Gopal Sharma",
      "userId": "12839894256006393174"
     },
     "user_tz": -330
    },
    "id": "CxpOAcNuZV3y",
    "outputId": "a2edf1a5-b483-43c4-c1cf-a75585dd2dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer is a new neural network architecture for sequence transduction tasks. It is based on attention mechanisms and does not use recurrence or convolutions. It achieves state-of-the-art results on machine translation and constituency parsing tasks.\n",
      "Transformer is a new neural network architecture for sequence transduction tasks. It eschews recurrence and instead relies entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "Transformer model consists of encoder and decoder stacks. Encoder stack has 6 identical layers, each with 2 sub-layers: multi-head self-attention and position-wise fully connected feed-forward network. Decoder stack has 3 sub-layers: multi-head self-attention, multi-head attention over the output of the encoder stack and position-wise fully connected feed-forward network.\n",
      "Attention is a mechanism that allows an AI model to focus on specific parts of a input sequence.\n",
      "It is used in the Transformer model to improve performance on a variety of natural language processing tasks.\n",
      "Transformer model consists of an encoder and decoder, each containing a stack of identical layers.\n",
      "The encoder layers contain multi-head attention and feed-forward networks. The decoder layers\n",
      "contain multi-head attention, feed-forward networks and an additional attention layer that attends\n",
      "to the encoder output.\n"
     ]
    }
   ],
   "source": [
    "summary = \"\"\n",
    "for i in range(len(new_text)):\n",
    "  prompt =f\"\"\"\n",
    "  Your task is to act as a Text Summariser.\n",
    "  I'll give you text from  pages of a book from beginning to end.\n",
    "  And your job is to summarise text from these pages in less than 100 words.\n",
    "  Don't be conversational. I need a plain 100 word answer.\n",
    "  Text is shared below, delimited with triple backticks:\n",
    "  ```{text[i]}```\n",
    "  \"\"\"\n",
    "  try:\n",
    "    response = get_completion(prompt)\n",
    "  except:\n",
    "    response = get_completion(prompt)\n",
    "  print(response)\n",
    "  summary= f\"{summary} {response}\\n\\n\"\n",
    "  # result.append(response)\n",
    "  time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SilyVEiX29Z"
   },
   "outputs": [],
   "source": [
    "with open(directory +'/palm_api_summary.txt',\n",
    "          'w') as out:\n",
    "  out.write(summary)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
